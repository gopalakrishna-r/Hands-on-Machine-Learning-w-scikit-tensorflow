{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NFRa4IjWixI6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from skimage.io import imread  # reading images\n",
        "from skimage.transform import resize  # resizing images\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from coders import LabelEncoder, DecodePredictions\n",
        "from retinamodels import RetinaNet\n",
        "from losses import RetinaNetLoss\n",
        "from RetinaNetUtils import get_backbone, preprocess_data, resize_and_pad_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxsY-Ti4A_ZD",
        "outputId": "6d1d380d-de92-483b-a931-2b77b38f68ec"
      },
      "outputs": [],
      "source": [
        "url = \"http://agristats.eu/images.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"images.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "with zipfile.ZipFile(\"images.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xWgxODNvixJR"
      },
      "outputs": [],
      "source": [
        "model_dir = \"retinanet/\"\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "num_classes = 80\n",
        "batch_size = 2\n",
        "\n",
        "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
        "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
        "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=learning_rate_boundaries, values=learning_rates\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4TwwSdqixJS",
        "outputId": "fc2a5d4e-8582-46b0-f13f-4c4800628526"
      },
      "outputs": [],
      "source": [
        "resnet50_backbone = get_backbone()\n",
        "loss_fn = RetinaNetLoss(num_classes)\n",
        "model = RetinaNet(num_classes, resnet50_backbone)\n",
        "\n",
        "optimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
        "model.compile(loss=loss_fn, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "YHKIAAlvixJT",
        "outputId": "d2ac10ee-f714-4579-f0db-f7df9aee2cdd"
      },
      "outputs": [],
      "source": [
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
        "        monitor=\"loss\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "\n",
        "import json\n",
        "import io\n",
        "# url = \"http://agristats.eu/images.json\"\n",
        "# filename = os.path.join(os.getcwd(), \"images.json\")\n",
        "# keras.utils.get_file(filename, url)\n",
        "with open('images.json') as json_file:\n",
        "    train_data = json.load(json_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "directory = os.fsencode(\"images\")\n",
        "for file in os.listdir(directory):\n",
        "  filename = os.fsdecode(file)\n",
        "  for item in train_data:\n",
        "    if filename == item[\"image/filename\"]: \n",
        "      image = load_img(os.path.join(\"./images/\", filename))\n",
        "      image = img_to_array(image)\n",
        "      item[\"image\"] = image\n",
        "      item[\"label\"] = random.randint(0,1)\n",
        "myimages = pd.DataFrame.from_dict(train_data).to_dict(\"list\")\n",
        "myimages = tf.data.Dataset.from_tensor_slices(myimages)\n",
        "\n",
        "crop_size = 300\n",
        "upscale_factor = 3\n",
        "input_size = crop_size // upscale_factor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "epochs = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_count = (tf.data.experimental.cardinality(myimages).numpy())\n",
        "image_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset_count = .8 * image_count\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0s0pHzFpixJV"
      },
      "outputs": [],
      "source": [
        "train_dataset = myimages.take(train_dataset_count)\n",
        "val_dataset = myimages.skip(train_dataset_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(176, 44)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#before preprocessing\n",
        "train_dataset_count = (tf.data.experimental.cardinality(train_dataset).numpy())\n",
        "val_dataset_count = (tf.data.experimental.cardinality(val_dataset).numpy())\n",
        "train_dataset_count, val_dataset_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5fIGzJ__ixJX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(87.0, 21.0)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Uncomment the following lines, when training on full dataset\n",
        "train_steps_per_epoch =  np.ceil((train_dataset_count/batch_size)-1)\n",
        "# val_steps_per_epoch = \\\n",
        "#     dataset_info.splits[\"validation\"].num_examples // batch_size\n",
        "\n",
        "\n",
        "validation_steps_per_epoch = np.ceil((val_dataset_count/batch_size)-1)\n",
        "# val_steps_per_epoch = \\\n",
        "#     dataset_info.splits[\"validation\"].num_examples // batch_size\n",
        "train_steps_per_epoch, validation_steps_per_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getdatashape(dataset):\n",
        "    for element in dataset:\n",
        "     print(element[0].shape)\n",
        "     break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9d40tC1aixJW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "samplebbox Tensor(\"args_1:0\", shape=(4,), dtype=float32)\n",
            "bbox Tensor(\"stack:0\", shape=(1, 4), dtype=float32)\n",
            "ασδ Tensor(\"concat:0\", shape=(1, 4), dtype=float32) Tensor(\"mul_1:0\", shape=(2,), dtype=float32)\n",
            "samplebbox Tensor(\"args_1:0\", shape=(4,), dtype=float32)\n",
            "bbox Tensor(\"stack:0\", shape=(1, 4), dtype=float32)\n",
            "ασδ Tensor(\"concat:0\", shape=(1, 4), dtype=float32) Tensor(\"mul_1:0\", shape=(2,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "autotune = tf.data.experimental.AUTOTUNE\n",
        "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "train_dataset = train_dataset.shuffle(8 * batch_size)\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
        ")\n",
        "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
        "\n",
        "train_dataset = train_dataset.repeat(epochs).batch(batch_size).prefetch(autotune)\n",
        "\n",
        "getdatashape(train_dataset)\n",
        "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "\n",
        "val_dataset = val_dataset.map(\n",
        "    label_encoder.encode_batch, num_parallel_calls=autotune)\n",
        "\n",
        "val_dataset = val_dataset.apply(tf.data.experimental.ignore_errors())\n",
        "\n",
        "val_dataset = val_dataset.repeat(epochs).batch(batch_size).prefetch(autotune)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 435.0 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "ename": "UnboundLocalError",
          "evalue": "local variable 'logs' referenced before assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-b004a33869a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
            "\u001b[1;32m~\\anaconda3\\envs\\d2l\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\d2l\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;31m# Run validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'logs' referenced before assignment"
          ]
        }
      ],
      "source": [
        "\n",
        "# Running 100 training and 50 validation steps,\n",
        "# remove `.take` when training on the full dataset\n",
        "\n",
        "# Running 100 training and 50 validation steps,\n",
        "# remove `.take` when training on the full dataset\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    validation_steps=validation_steps_per_epoch,\n",
        "    batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdDB82RtixJZ"
      },
      "outputs": [],
      "source": [
        "# Change this to `model_dir` when not using the downloaded weights\n",
        "weights_dir = model_dir\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
        "model.load_weights(latest_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhPTsdN4ixJa"
      },
      "outputs": [],
      "source": [
        "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
        "predictions = model(image, training=False)\n",
        "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
        "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wryO8KvmixJh"
      },
      "outputs": [],
      "source": [
        "def prepare_image(image):\n",
        "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
        "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
        "    return tf.expand_dims(image, axis=0), ratio\n",
        "\n",
        "\n",
        "val_dataset = tfds.load(\"coco/2017\", split=\"validation\", data_dir=\"data\")\n",
        "int2str = dataset_info.features[\"label\"].int2str\n",
        "\n",
        "image = load_img('test1.jpg')\n",
        "image = img_to_array(image)\n",
        "\n",
        "input_image, ratio = prepare_image(image)\n",
        "detections = inference_model.predict(input_image)\n",
        "num_detections = detections.valid_detections[0]\n",
        "class_names = [\n",
        "    int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]\n",
        "]\n",
        "visualize_detections(\n",
        "    image,\n",
        "    detections.nmsed_boxes[0][:num_detections] / ratio,\n",
        "    class_names,\n",
        "    detections.nmsed_scores[0][:num_detections],\n",
        ")\n",
        "\n",
        "#for sample in val_dataset.take(4):\n",
        "#    print(sample[\"image\"])\n",
        "#    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
        "#    input_image, ratio = prepare_image(image)\n",
        "#    detections = inference_model.predict(input_image)\n",
        "#    num_detections = detections.valid_detections[0]\n",
        "#    class_names = [\n",
        "#        int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]\n",
        "#    ]\n",
        "#    visualize_detections(\n",
        "#        image,\n",
        "#        detections.nmsed_boxes[0][:num_detections] / ratio,\n",
        "#        class_names,\n",
        "#        detections.nmsed_scores[0][:num_detections],\n",
        "#    )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "objectDetection_SO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
