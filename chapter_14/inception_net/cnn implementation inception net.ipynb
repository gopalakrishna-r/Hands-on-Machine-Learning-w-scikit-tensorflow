{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%load_ext tensorboard\n",
    "import easydict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..', 'CIFAR'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from CIFARLoader import save_cifar_fit, check_cifar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_session():\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True, \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True, \n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rescale= 1./255, \n",
    "    rotation_range=40, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range= 0.2, \n",
    "    shear_range= 0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest', \n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                                  samplewise_center=False,\n",
    "                                  featurewise_std_normalization=True,\n",
    "                                  samplewise_std_normalization=False,\n",
    "                                  zca_whitening=False,\n",
    "                                  zca_epsilon=1e-06,\n",
    "                                  rescale=1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '..\\\\CIFAR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...|/-\\|/-\\|/-\\|/-\\|/-\\|/-\\|/-\\|/-\\|/-\\|/-                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving train images: 100%|██████████| 50000/50000 [00:18<00:00, 2641.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     /-\\|/-\\|/-\\|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving test images: 100%|██████████| 10000/10000 [00:03<00:00, 2624.68it/s]\n"
     ]
    }
   ],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"dataset\": \"cifar10\",\n",
    "    \"output\": OUTPUT_DIR,\n",
    "    \"name_with_batch_index\": False\n",
    "})\n",
    "\n",
    "if check_cifar(args.dataset, OUTPUT_DIR) :\n",
    "    save_cifar_fit(args, train_datagen, test_datagen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 900.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "IMAGE_COUNT = len(glob.glob(OUTPUT_DIR + '/' + 'train'  + '/*/*'))\n",
    "BATCH_SIZE = 50\n",
    "STEPS_PER_EPOCH = np.ceil((IMAGE_COUNT - IMAGE_COUNT * VALIDATION_SPLIT)/BATCH_SIZE)\n",
    "IMAGE_COUNT, STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 images belonging to 10 classes.\n",
      "Found 5000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    OUTPUT_DIR + '/' + 'train', \n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode='categorical', \n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    OUTPUT_DIR + '/' + 'train',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inception net/ google net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from InceptionModules import InceptionStem\n",
    "\n",
    "date_time = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "image_net_model = InceptionStem()\n",
    "image_net_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"image_net_model_\" + date_time + \".h5\", overwrite=True, save_best_only=True)\n",
    "\n",
    "run_index = 1\n",
    "run_log_dir = Path(Path().resolve(), \"cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_log_dir)\n",
    "\n",
    "callbacks  = [model_checkpoint, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net_model.compile(loss=tf.losses.CategoricalCrossentropy(), metrics=[\n",
    "                       'accuracy'], optimizer=tf.optimizers.Adam(learning_rate=0.0001))\n",
    "\n",
    "history = image_net_model.fit(train_generator, validation_data=validation_generator,\n",
    "    callbacks=[callbacks], verbose=2, workers=6, \n",
    "    epochs=100, steps_per_epoch=STEPS_PER_EPOCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    OUTPUT_DIR + '/' + 'test', target_size=TARGET_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = image_net_model.evaluate(test_generator, workers=8,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "loss = history.history['loss'][-1]\n",
    "val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(\"Training accuracy: \", acc)\n",
    "print(\"Training loss: \", loss)\n",
    "\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "print(\"Validation loss: \", val_loss)\n",
    "\n",
    "# Plotting the graphs to visualize the trend of accuracy and loss\n",
    "\n",
    "epochs = range(1, len(history.history['accuracy'])+1)\n",
    "\n",
    "plt.plot(epochs, history.history['accuracy'], 'bo', label='Training acc')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, history.history['loss'], 'bo', label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "360eb45faca1e4dfefc4f13aa9499776008d91528b4d443d812d58097d713eb4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('d2l': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
