{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import ssl\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_session():\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense, \n",
    "                              kernel_initializer = keras.initializers.he_normal(), \n",
    "                              activation = tf.nn.elu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(RegularizedDense(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(X_train_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( keras.layers.Dense(10, activation= tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Nadam(lr = 5e-5),\n",
    "              loss= keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_model.h5\" , save_best_only=True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8724), started 2 days, 17:25:17 ago. (Use '!kill 8724' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ffe43c00f374dcba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ffe43c00f374dcba\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./cifar10_logs --port=6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\goofy\\d2l\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0507s). Check your callbacks.\n",
      "352/352 - 5s - loss: 9.3682 - accuracy: 0.1266 - val_loss: 2.6384 - val_accuracy: 0.1542\n",
      "Epoch 2/100\n",
      "352/352 - 4s - loss: 2.3691 - accuracy: 0.1826 - val_loss: 2.1942 - val_accuracy: 0.2126\n",
      "Epoch 3/100\n",
      "352/352 - 4s - loss: 2.1322 - accuracy: 0.2317 - val_loss: 2.0738 - val_accuracy: 0.2612\n",
      "Epoch 4/100\n",
      "352/352 - 5s - loss: 2.0402 - accuracy: 0.2617 - val_loss: 2.0124 - val_accuracy: 0.2760\n",
      "Epoch 5/100\n",
      "352/352 - 5s - loss: 1.9837 - accuracy: 0.2797 - val_loss: 1.9597 - val_accuracy: 0.2868\n",
      "Epoch 6/100\n",
      "352/352 - 4s - loss: 1.9401 - accuracy: 0.2961 - val_loss: 1.9146 - val_accuracy: 0.3164\n",
      "Epoch 7/100\n",
      "352/352 - 4s - loss: 1.9028 - accuracy: 0.3091 - val_loss: 1.8970 - val_accuracy: 0.3098\n",
      "Epoch 8/100\n",
      "352/352 - 5s - loss: 1.8707 - accuracy: 0.3199 - val_loss: 1.8566 - val_accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "352/352 - 5s - loss: 1.8424 - accuracy: 0.3300 - val_loss: 1.8375 - val_accuracy: 0.3346\n",
      "Epoch 10/100\n",
      "352/352 - 4s - loss: 1.8161 - accuracy: 0.3385 - val_loss: 1.8806 - val_accuracy: 0.3122\n",
      "Epoch 11/100\n",
      "352/352 - 4s - loss: 1.7930 - accuracy: 0.3473 - val_loss: 1.8059 - val_accuracy: 0.3572\n",
      "Epoch 12/100\n",
      "352/352 - 4s - loss: 1.7697 - accuracy: 0.3574 - val_loss: 1.8034 - val_accuracy: 0.3404\n",
      "Epoch 13/100\n",
      "352/352 - 5s - loss: 1.7480 - accuracy: 0.3624 - val_loss: 1.7551 - val_accuracy: 0.3628\n",
      "Epoch 14/100\n",
      "352/352 - 4s - loss: 1.7274 - accuracy: 0.3724 - val_loss: 1.7802 - val_accuracy: 0.3550\n",
      "Epoch 15/100\n",
      "352/352 - 5s - loss: 1.7032 - accuracy: 0.3783 - val_loss: 1.7302 - val_accuracy: 0.3730\n",
      "Epoch 16/100\n",
      "352/352 - 4s - loss: 1.6853 - accuracy: 0.3897 - val_loss: 1.7226 - val_accuracy: 0.3748\n",
      "Epoch 17/100\n",
      "352/352 - 4s - loss: 1.6666 - accuracy: 0.3972 - val_loss: 1.7102 - val_accuracy: 0.3816\n",
      "Epoch 18/100\n",
      "352/352 - 4s - loss: 1.6478 - accuracy: 0.4033 - val_loss: 1.7221 - val_accuracy: 0.3720\n",
      "Epoch 19/100\n",
      "352/352 - 4s - loss: 1.6300 - accuracy: 0.4108 - val_loss: 1.6905 - val_accuracy: 0.3880\n",
      "Epoch 20/100\n",
      "352/352 - 4s - loss: 1.6121 - accuracy: 0.4162 - val_loss: 1.6714 - val_accuracy: 0.3888\n",
      "Epoch 21/100\n",
      "352/352 - 4s - loss: 1.5971 - accuracy: 0.4208 - val_loss: 1.6672 - val_accuracy: 0.3950\n",
      "Epoch 22/100\n",
      "352/352 - 4s - loss: 1.5807 - accuracy: 0.4282 - val_loss: 1.6789 - val_accuracy: 0.3906\n",
      "Epoch 23/100\n",
      "352/352 - 4s - loss: 1.5672 - accuracy: 0.4338 - val_loss: 1.6447 - val_accuracy: 0.4020\n",
      "Epoch 24/100\n",
      "352/352 - 4s - loss: 1.5523 - accuracy: 0.4356 - val_loss: 1.6639 - val_accuracy: 0.4012\n",
      "Epoch 25/100\n",
      "352/352 - 5s - loss: 1.5403 - accuracy: 0.4429 - val_loss: 1.6212 - val_accuracy: 0.4138\n",
      "Epoch 26/100\n",
      "352/352 - 4s - loss: 1.5273 - accuracy: 0.4470 - val_loss: 1.6461 - val_accuracy: 0.3960\n",
      "Epoch 27/100\n",
      "352/352 - 5s - loss: 1.5106 - accuracy: 0.4532 - val_loss: 1.6318 - val_accuracy: 0.4036\n",
      "Epoch 28/100\n",
      "352/352 - 5s - loss: 1.5038 - accuracy: 0.4572 - val_loss: 1.6344 - val_accuracy: 0.4094\n",
      "Epoch 29/100\n",
      "352/352 - 4s - loss: 1.4903 - accuracy: 0.4617 - val_loss: 1.6070 - val_accuracy: 0.4138\n",
      "Epoch 30/100\n",
      "352/352 - 4s - loss: 1.4779 - accuracy: 0.4658 - val_loss: 1.6234 - val_accuracy: 0.4120\n",
      "Epoch 31/100\n",
      "352/352 - 4s - loss: 1.4702 - accuracy: 0.4681 - val_loss: 1.5903 - val_accuracy: 0.4262\n",
      "Epoch 32/100\n",
      "352/352 - 4s - loss: 1.4581 - accuracy: 0.4742 - val_loss: 1.6002 - val_accuracy: 0.4222\n",
      "Epoch 33/100\n",
      "352/352 - 5s - loss: 1.4509 - accuracy: 0.4763 - val_loss: 1.5883 - val_accuracy: 0.4294\n",
      "Epoch 34/100\n",
      "352/352 - 4s - loss: 1.4355 - accuracy: 0.4834 - val_loss: 1.5735 - val_accuracy: 0.4298\n",
      "Epoch 35/100\n",
      "352/352 - 4s - loss: 1.4256 - accuracy: 0.4847 - val_loss: 1.6003 - val_accuracy: 0.4192\n",
      "Epoch 36/100\n",
      "352/352 - 4s - loss: 1.4174 - accuracy: 0.4915 - val_loss: 1.5817 - val_accuracy: 0.4372\n",
      "Epoch 37/100\n",
      "352/352 - 4s - loss: 1.4078 - accuracy: 0.4934 - val_loss: 1.5811 - val_accuracy: 0.4328\n",
      "Epoch 38/100\n",
      "352/352 - 4s - loss: 1.3981 - accuracy: 0.4961 - val_loss: 1.5811 - val_accuracy: 0.4266\n",
      "Epoch 39/100\n",
      "352/352 - 5s - loss: 1.3870 - accuracy: 0.5000 - val_loss: 1.5937 - val_accuracy: 0.4316\n",
      "Epoch 40/100\n",
      "352/352 - 4s - loss: 1.3793 - accuracy: 0.5037 - val_loss: 1.5994 - val_accuracy: 0.4282\n",
      "Epoch 41/100\n",
      "352/352 - 5s - loss: 1.3700 - accuracy: 0.5081 - val_loss: 1.6017 - val_accuracy: 0.4350\n",
      "Epoch 42/100\n",
      "352/352 - 5s - loss: 1.3611 - accuracy: 0.5121 - val_loss: 1.5638 - val_accuracy: 0.4400\n",
      "Epoch 43/100\n",
      "352/352 - 5s - loss: 1.3547 - accuracy: 0.5146 - val_loss: 1.5754 - val_accuracy: 0.4344\n",
      "Epoch 44/100\n",
      "352/352 - 4s - loss: 1.3450 - accuracy: 0.5136 - val_loss: 1.5907 - val_accuracy: 0.4364\n",
      "Epoch 45/100\n",
      "352/352 - 5s - loss: 1.3378 - accuracy: 0.5202 - val_loss: 1.5819 - val_accuracy: 0.4432\n",
      "Epoch 46/100\n",
      "352/352 - 4s - loss: 1.3280 - accuracy: 0.5251 - val_loss: 1.5754 - val_accuracy: 0.4424\n",
      "Epoch 47/100\n",
      "352/352 - 4s - loss: 1.3174 - accuracy: 0.5265 - val_loss: 1.5843 - val_accuracy: 0.4382\n",
      "Epoch 48/100\n",
      "352/352 - 4s - loss: 1.3151 - accuracy: 0.5271 - val_loss: 1.5879 - val_accuracy: 0.4352\n",
      "Epoch 49/100\n",
      "352/352 - 4s - loss: 1.3023 - accuracy: 0.5327 - val_loss: 1.5958 - val_accuracy: 0.4438\n",
      "Epoch 50/100\n",
      "352/352 - 4s - loss: 1.2960 - accuracy: 0.5352 - val_loss: 1.5848 - val_accuracy: 0.4412\n",
      "Epoch 51/100\n",
      "352/352 - 5s - loss: 1.2902 - accuracy: 0.5371 - val_loss: 1.6296 - val_accuracy: 0.4290\n",
      "Epoch 52/100\n",
      "352/352 - 5s - loss: 1.2826 - accuracy: 0.5379 - val_loss: 1.5848 - val_accuracy: 0.4484\n",
      "Epoch 53/100\n",
      "352/352 - 4s - loss: 1.2734 - accuracy: 0.5419 - val_loss: 1.5914 - val_accuracy: 0.4476\n",
      "Epoch 54/100\n",
      "352/352 - 4s - loss: 1.2682 - accuracy: 0.5436 - val_loss: 1.6119 - val_accuracy: 0.4404\n",
      "Epoch 55/100\n",
      "352/352 - 4s - loss: 1.2627 - accuracy: 0.5472 - val_loss: 1.5783 - val_accuracy: 0.4516\n",
      "Epoch 56/100\n",
      "352/352 - 5s - loss: 1.2518 - accuracy: 0.5523 - val_loss: 1.5817 - val_accuracy: 0.4492\n",
      "Epoch 57/100\n",
      "352/352 - 4s - loss: 1.2449 - accuracy: 0.5549 - val_loss: 1.5893 - val_accuracy: 0.4436\n",
      "Epoch 58/100\n",
      "352/352 - 4s - loss: 1.2398 - accuracy: 0.5535 - val_loss: 1.6389 - val_accuracy: 0.4332\n",
      "Epoch 59/100\n",
      "352/352 - 4s - loss: 1.2331 - accuracy: 0.5565 - val_loss: 1.5896 - val_accuracy: 0.4500\n",
      "Epoch 60/100\n",
      "352/352 - 4s - loss: 1.2253 - accuracy: 0.5594 - val_loss: 1.6041 - val_accuracy: 0.4452\n",
      "Epoch 61/100\n",
      "352/352 - 4s - loss: 1.2201 - accuracy: 0.5614 - val_loss: 1.6074 - val_accuracy: 0.4400\n",
      "Epoch 62/100\n",
      "352/352 - 5s - loss: 1.2128 - accuracy: 0.5652 - val_loss: 1.6099 - val_accuracy: 0.4448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bf42be0c08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs= 100, verbose = 2, \n",
    "          validation_data=(X_valid, y_valid), callbacks = callbacks, workers = 0, batch_size= 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5638 - accuracy: 0.0766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5637822151184082, 0.07660000026226044]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(\"cifar10_model.h5\")\n",
    "loaded_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr= 5e-4)\n",
    "model.compile(optimizer = optimizer, loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_stopping_cb = keras.callbacks.ModelCheckpoint(\"cifar10_bn_model.h5\", save_best_only = True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_log_dir\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "                         \n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "          epochs = 100, workers = 0 , \n",
    "          callbacks = [early_stopping_cb, model_stopping_cb, tensorboard_cb])\n",
    "\n",
    "best_model = keras.models.load_model(\"cifar10_bn_model.h5\")\n",
    "\n",
    "best_model.evaluate(X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.lecun_normal, activation=tf.nn.selu))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(7e-4)\n",
    "model.compile(optimizer = optimizer, loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis = 0)\n",
    "X_stds = X_train.stds(axis = 0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), callbacks = callbacks, workers= 0)\n",
    "\n",
    "loaded_model = keras.models.load_model(\"cifar10_selu_model.h5\")\n",
    "loaded_model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.lecun_normal, activation=tf.nn.selu))\n",
    "model.add(keras.layers.AlphaDropout(rate = 0.1))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "360eb45faca1e4dfefc4f13aa9499776008d91528b4d443d812d58097d713eb4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('d2l': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
