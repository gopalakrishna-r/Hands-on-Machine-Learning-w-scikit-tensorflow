{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import ssl\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_session():\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense, \n",
    "                              kernel_initializer = keras.initializers.he_normal(), \n",
    "                              activation = tf.nn.elu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(RegularizedDense(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(X_train_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( keras.layers.Dense(10, activation= tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Nadam(lr = 5e-5),\n",
    "              loss= keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_model.h5\" ,overwrite=True, save_best_only=True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8724), started 4 days, 0:22:01 ago. (Use '!kill 8724' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b33774ed8574d05c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b33774ed8574d05c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./cifar10_logs --port=6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\goofy\\d2l\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.0487s). Check your callbacks.\n",
      "352/352 - 5s - loss: 6.0791 - accuracy: 0.1308 - val_loss: 2.4262 - val_accuracy: 0.1676\n",
      "Epoch 2/100\n",
      "352/352 - 5s - loss: 2.2648 - accuracy: 0.1892 - val_loss: 2.1437 - val_accuracy: 0.2178\n",
      "Epoch 3/100\n",
      "352/352 - 5s - loss: 2.0947 - accuracy: 0.2323 - val_loss: 2.0509 - val_accuracy: 0.2424\n",
      "Epoch 4/100\n",
      "352/352 - 5s - loss: 2.0097 - accuracy: 0.2590 - val_loss: 1.9682 - val_accuracy: 0.2828\n",
      "Epoch 5/100\n",
      "352/352 - 4s - loss: 1.9529 - accuracy: 0.2843 - val_loss: 1.9471 - val_accuracy: 0.2826\n",
      "Epoch 6/100\n",
      "352/352 - 4s - loss: 1.9094 - accuracy: 0.3030 - val_loss: 1.8773 - val_accuracy: 0.3186\n",
      "Epoch 7/100\n",
      "352/352 - 4s - loss: 1.8718 - accuracy: 0.3140 - val_loss: 1.9217 - val_accuracy: 0.2952\n",
      "Epoch 8/100\n",
      "352/352 - 4s - loss: 1.8417 - accuracy: 0.3273 - val_loss: 1.9003 - val_accuracy: 0.2996\n",
      "Epoch 9/100\n",
      "352/352 - 4s - loss: 1.8109 - accuracy: 0.3397 - val_loss: 1.8204 - val_accuracy: 0.3318\n",
      "Epoch 10/100\n",
      "352/352 - 5s - loss: 1.7845 - accuracy: 0.3473 - val_loss: 1.7862 - val_accuracy: 0.3462\n",
      "Epoch 11/100\n",
      "352/352 - 5s - loss: 1.7632 - accuracy: 0.3597 - val_loss: 1.7673 - val_accuracy: 0.3530\n",
      "Epoch 12/100\n",
      "352/352 - 4s - loss: 1.7404 - accuracy: 0.3639 - val_loss: 1.7896 - val_accuracy: 0.3506\n",
      "Epoch 13/100\n",
      "352/352 - 5s - loss: 1.7170 - accuracy: 0.3758 - val_loss: 1.7422 - val_accuracy: 0.3568\n",
      "Epoch 14/100\n",
      "352/352 - 4s - loss: 1.6989 - accuracy: 0.3800 - val_loss: 1.7243 - val_accuracy: 0.3658\n",
      "Epoch 15/100\n",
      "352/352 - 4s - loss: 1.6764 - accuracy: 0.3924 - val_loss: 1.7350 - val_accuracy: 0.3666\n",
      "Epoch 16/100\n",
      "352/352 - 4s - loss: 1.6576 - accuracy: 0.4001 - val_loss: 1.7063 - val_accuracy: 0.3838\n",
      "Epoch 17/100\n",
      "352/352 - 4s - loss: 1.6355 - accuracy: 0.4068 - val_loss: 1.6830 - val_accuracy: 0.3902\n",
      "Epoch 18/100\n",
      "352/352 - 4s - loss: 1.6188 - accuracy: 0.4144 - val_loss: 1.7013 - val_accuracy: 0.3778\n",
      "Epoch 19/100\n",
      "352/352 - 5s - loss: 1.6004 - accuracy: 0.4189 - val_loss: 1.6756 - val_accuracy: 0.3952\n",
      "Epoch 20/100\n",
      "352/352 - 5s - loss: 1.5828 - accuracy: 0.4267 - val_loss: 1.6671 - val_accuracy: 0.3922\n",
      "Epoch 21/100\n",
      "352/352 - 5s - loss: 1.5704 - accuracy: 0.4301 - val_loss: 1.6424 - val_accuracy: 0.4002\n",
      "Epoch 22/100\n",
      "352/352 - 5s - loss: 1.5537 - accuracy: 0.4384 - val_loss: 1.6384 - val_accuracy: 0.4038\n",
      "Epoch 23/100\n",
      "352/352 - 4s - loss: 1.5383 - accuracy: 0.4438 - val_loss: 1.7127 - val_accuracy: 0.3874\n",
      "Epoch 24/100\n",
      "352/352 - 5s - loss: 1.5245 - accuracy: 0.4497 - val_loss: 1.6144 - val_accuracy: 0.4168\n",
      "Epoch 25/100\n",
      "352/352 - 5s - loss: 1.5109 - accuracy: 0.4569 - val_loss: 1.6039 - val_accuracy: 0.4230\n",
      "Epoch 26/100\n",
      "352/352 - 4s - loss: 1.4997 - accuracy: 0.4605 - val_loss: 1.6127 - val_accuracy: 0.4228\n",
      "Epoch 27/100\n",
      "352/352 - 4s - loss: 1.4862 - accuracy: 0.4639 - val_loss: 1.6102 - val_accuracy: 0.4234\n",
      "Epoch 28/100\n",
      "352/352 - 4s - loss: 1.4716 - accuracy: 0.4691 - val_loss: 1.5852 - val_accuracy: 0.4292\n",
      "Epoch 29/100\n",
      "352/352 - 5s - loss: 1.4606 - accuracy: 0.4728 - val_loss: 1.5955 - val_accuracy: 0.4210\n",
      "Epoch 30/100\n",
      "352/352 - 4s - loss: 1.4491 - accuracy: 0.4786 - val_loss: 1.5689 - val_accuracy: 0.4354\n",
      "Epoch 31/100\n",
      "352/352 - 4s - loss: 1.4393 - accuracy: 0.4792 - val_loss: 1.5894 - val_accuracy: 0.4312\n",
      "Epoch 32/100\n",
      "352/352 - 4s - loss: 1.4253 - accuracy: 0.4864 - val_loss: 1.5777 - val_accuracy: 0.4354\n",
      "Epoch 33/100\n",
      "352/352 - 4s - loss: 1.4169 - accuracy: 0.4897 - val_loss: 1.5900 - val_accuracy: 0.4302\n",
      "Epoch 34/100\n",
      "352/352 - 4s - loss: 1.4081 - accuracy: 0.4926 - val_loss: 1.5900 - val_accuracy: 0.4292\n",
      "Epoch 35/100\n",
      "352/352 - 4s - loss: 1.3972 - accuracy: 0.4961 - val_loss: 1.5638 - val_accuracy: 0.4412\n",
      "Epoch 36/100\n",
      "352/352 - 4s - loss: 1.3861 - accuracy: 0.5040 - val_loss: 1.5577 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "352/352 - 4s - loss: 1.3754 - accuracy: 0.5056 - val_loss: 1.5855 - val_accuracy: 0.4330\n",
      "Epoch 38/100\n",
      "352/352 - 4s - loss: 1.3670 - accuracy: 0.5076 - val_loss: 1.5709 - val_accuracy: 0.4424\n",
      "Epoch 39/100\n",
      "352/352 - 4s - loss: 1.3577 - accuracy: 0.5120 - val_loss: 1.5425 - val_accuracy: 0.4450\n",
      "Epoch 40/100\n",
      "352/352 - 4s - loss: 1.3489 - accuracy: 0.5138 - val_loss: 1.5704 - val_accuracy: 0.4372\n",
      "Epoch 41/100\n",
      "352/352 - 4s - loss: 1.3418 - accuracy: 0.5163 - val_loss: 1.5734 - val_accuracy: 0.4398\n",
      "Epoch 42/100\n",
      "352/352 - 4s - loss: 1.3299 - accuracy: 0.5189 - val_loss: 1.5563 - val_accuracy: 0.4468\n",
      "Epoch 43/100\n",
      "352/352 - 4s - loss: 1.3236 - accuracy: 0.5242 - val_loss: 1.5599 - val_accuracy: 0.4414\n",
      "Epoch 44/100\n",
      "352/352 - 4s - loss: 1.3155 - accuracy: 0.5274 - val_loss: 1.5688 - val_accuracy: 0.4382\n",
      "Epoch 45/100\n",
      "352/352 - 4s - loss: 1.3089 - accuracy: 0.5280 - val_loss: 1.5592 - val_accuracy: 0.4446\n",
      "Epoch 46/100\n",
      "352/352 - 4s - loss: 1.2971 - accuracy: 0.5343 - val_loss: 1.5632 - val_accuracy: 0.4540\n",
      "Epoch 47/100\n",
      "352/352 - 4s - loss: 1.2895 - accuracy: 0.5360 - val_loss: 1.5767 - val_accuracy: 0.4456\n",
      "Epoch 48/100\n",
      "352/352 - 4s - loss: 1.2816 - accuracy: 0.5372 - val_loss: 1.6493 - val_accuracy: 0.4326\n",
      "Epoch 49/100\n",
      "352/352 - 4s - loss: 1.2756 - accuracy: 0.5435 - val_loss: 1.5750 - val_accuracy: 0.4452\n",
      "Epoch 50/100\n",
      "352/352 - 4s - loss: 1.2697 - accuracy: 0.5426 - val_loss: 1.5616 - val_accuracy: 0.4480\n",
      "Epoch 51/100\n",
      "352/352 - 4s - loss: 1.2603 - accuracy: 0.5465 - val_loss: 1.5820 - val_accuracy: 0.4474\n",
      "Epoch 52/100\n",
      "352/352 - 4s - loss: 1.2506 - accuracy: 0.5515 - val_loss: 1.5557 - val_accuracy: 0.4594\n",
      "Epoch 53/100\n",
      "352/352 - 4s - loss: 1.2445 - accuracy: 0.5525 - val_loss: 1.5751 - val_accuracy: 0.4628\n",
      "Epoch 54/100\n",
      "352/352 - 4s - loss: 1.2392 - accuracy: 0.5538 - val_loss: 1.5629 - val_accuracy: 0.4546\n",
      "Epoch 55/100\n",
      "352/352 - 4s - loss: 1.2297 - accuracy: 0.5573 - val_loss: 1.5734 - val_accuracy: 0.4550\n",
      "Epoch 56/100\n",
      "352/352 - 4s - loss: 1.2196 - accuracy: 0.5619 - val_loss: 1.5895 - val_accuracy: 0.4510\n",
      "Epoch 57/100\n",
      "352/352 - 4s - loss: 1.2141 - accuracy: 0.5649 - val_loss: 1.5856 - val_accuracy: 0.4550\n",
      "Epoch 58/100\n",
      "352/352 - 4s - loss: 1.2100 - accuracy: 0.5657 - val_loss: 1.5768 - val_accuracy: 0.4592\n",
      "Epoch 59/100\n",
      "352/352 - 4s - loss: 1.2014 - accuracy: 0.5699 - val_loss: 1.5904 - val_accuracy: 0.4510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x211b5e30b08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs= 100, verbose = 2, \n",
    "          validation_data=(X_valid, y_valid), callbacks = callbacks, workers = 0, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5425 - accuracy: 0.1108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5424939393997192, 0.11079999804496765]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(\"cifar10_model.h5\")\n",
    "loaded_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/352 [..............................] - ETA: 1:33 - loss: 2.7342 - accuracy: 0.1133WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0405s vs `on_train_batch_end` time: 0.4956s). Check your callbacks.\n",
      "352/352 [==============================] - 12s 35ms/step - loss: 1.7604 - accuracy: 0.3741 - val_loss: 1.5920 - val_accuracy: 0.4316\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 13s 37ms/step - loss: 1.5374 - accuracy: 0.4551 - val_loss: 1.5532 - val_accuracy: 0.4448\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 13s 36ms/step - loss: 1.4486 - accuracy: 0.4850 - val_loss: 1.4917 - val_accuracy: 0.4694\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 1.3873 - accuracy: 0.5062 - val_loss: 1.4730 - val_accuracy: 0.4834\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 12s 34ms/step - loss: 1.3348 - accuracy: 0.5264 - val_loss: 1.4279 - val_accuracy: 0.4894\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 12s 33ms/step - loss: 1.2913 - accuracy: 0.5420 - val_loss: 1.4242 - val_accuracy: 0.4936\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 12s 33ms/step - loss: 1.2500 - accuracy: 0.5575 - val_loss: 1.4299 - val_accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 12s 35ms/step - loss: 1.2151 - accuracy: 0.5686 - val_loss: 1.3965 - val_accuracy: 0.5110\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 12s 35ms/step - loss: 1.1776 - accuracy: 0.5844 - val_loss: 1.4252 - val_accuracy: 0.5066\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 1.1485 - accuracy: 0.5933 - val_loss: 1.3804 - val_accuracy: 0.5278\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 1.1199 - accuracy: 0.6049 - val_loss: 1.4133 - val_accuracy: 0.5150\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 12s 35ms/step - loss: 1.0871 - accuracy: 0.6158 - val_loss: 1.4054 - val_accuracy: 0.5154\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 1.0609 - accuracy: 0.6229 - val_loss: 1.4200 - val_accuracy: 0.5174\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 1.0370 - accuracy: 0.6306 - val_loss: 1.4053 - val_accuracy: 0.5228\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 13s 37ms/step - loss: 1.0133 - accuracy: 0.6380 - val_loss: 1.4226 - val_accuracy: 0.5266\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 12s 35ms/step - loss: 0.9868 - accuracy: 0.6514 - val_loss: 1.4535 - val_accuracy: 0.5202\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.9622 - accuracy: 0.6577 - val_loss: 1.4395 - val_accuracy: 0.5266\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 12s 34ms/step - loss: 0.9418 - accuracy: 0.6646 - val_loss: 1.4477 - val_accuracy: 0.5242\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.9226 - accuracy: 0.6719 - val_loss: 1.4997 - val_accuracy: 0.5122\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.9047 - accuracy: 0.6788 - val_loss: 1.4968 - val_accuracy: 0.5188\n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 12s 33ms/step - loss: 0.8849 - accuracy: 0.6880 - val_loss: 1.4991 - val_accuracy: 0.5174\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.8640 - accuracy: 0.6948 - val_loss: 1.5292 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 12s 34ms/step - loss: 0.8443 - accuracy: 0.7005 - val_loss: 1.5054 - val_accuracy: 0.5254\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 12s 33ms/step - loss: 0.8288 - accuracy: 0.7080 - val_loss: 1.5029 - val_accuracy: 0.5256\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 12s 33ms/step - loss: 0.8134 - accuracy: 0.7122 - val_loss: 1.5428 - val_accuracy: 0.5130\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.7962 - accuracy: 0.7166 - val_loss: 1.5536 - val_accuracy: 0.5084\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 11s 33ms/step - loss: 0.7782 - accuracy: 0.7242 - val_loss: 1.5808 - val_accuracy: 0.5144\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.7644 - accuracy: 0.7293 - val_loss: 1.5750 - val_accuracy: 0.5224\n",
      "Epoch 29/100\n",
      "352/352 [==============================] - 11s 32ms/step - loss: 0.7523 - accuracy: 0.7342 - val_loss: 1.5787 - val_accuracy: 0.5218\n",
      "Epoch 30/100\n",
      "352/352 [==============================] - 12s 35ms/step - loss: 0.7332 - accuracy: 0.7384 - val_loss: 1.6229 - val_accuracy: 0.5148\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3804 - accuracy: 0.0912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3803691864013672, 0.09120000153779984]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr= 5e-4)\n",
    "model.compile(optimizer = optimizer, loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_stopping_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\",overwrite=True, save_best_only = True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_log_dir\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "                         \n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "          epochs = 100, workers = 0 , \n",
    "          callbacks = [early_stopping_cb, model_stopping_cb, tensorboard_cb] ,batch_size=128)\n",
    "\n",
    "best_model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "\n",
    "best_model.evaluate(X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.lecun_normal(), activation=tf.nn.selu))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(7e-4)\n",
    "model.compile(optimizer = optimizer, loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/352 [..............................] - ETA: 36s - loss: 2.9301 - accuracy: 0.1055WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0137s vs `on_train_batch_end` time: 0.1940s). Check your callbacks.\n",
      "352/352 [==============================] - 5s 15ms/step - loss: 1.8765 - accuracy: 0.3294 - val_loss: 1.7422 - val_accuracy: 0.3848\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.6560 - accuracy: 0.4122 - val_loss: 1.6165 - val_accuracy: 0.4300\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.5571 - accuracy: 0.4474 - val_loss: 1.5775 - val_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.4794 - accuracy: 0.4770 - val_loss: 1.5460 - val_accuracy: 0.4594\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.4134 - accuracy: 0.5036 - val_loss: 1.5835 - val_accuracy: 0.4486\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.3604 - accuracy: 0.5190 - val_loss: 1.4881 - val_accuracy: 0.4808\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.3081 - accuracy: 0.5389 - val_loss: 1.5410 - val_accuracy: 0.4576\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 5s 15ms/step - loss: 1.2623 - accuracy: 0.5578 - val_loss: 1.4646 - val_accuracy: 0.4958\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.2207 - accuracy: 0.5715 - val_loss: 1.4797 - val_accuracy: 0.4852\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 5s 15ms/step - loss: 1.1776 - accuracy: 0.5893 - val_loss: 1.4638 - val_accuracy: 0.4990\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.1456 - accuracy: 0.6006 - val_loss: 1.4660 - val_accuracy: 0.4986\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.1031 - accuracy: 0.6164 - val_loss: 1.4884 - val_accuracy: 0.4974\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.0679 - accuracy: 0.6290 - val_loss: 1.4937 - val_accuracy: 0.4994\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.0389 - accuracy: 0.6397 - val_loss: 1.4850 - val_accuracy: 0.5104\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.0103 - accuracy: 0.6488 - val_loss: 1.5094 - val_accuracy: 0.5018\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9755 - accuracy: 0.6618 - val_loss: 1.5620 - val_accuracy: 0.5008\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9518 - accuracy: 0.6708 - val_loss: 1.5157 - val_accuracy: 0.5180\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.9172 - accuracy: 0.6828 - val_loss: 1.5642 - val_accuracy: 0.5152\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8929 - accuracy: 0.6907 - val_loss: 1.6265 - val_accuracy: 0.4998\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.8691 - accuracy: 0.6994 - val_loss: 1.6191 - val_accuracy: 0.5102\n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8440 - accuracy: 0.7109 - val_loss: 1.6312 - val_accuracy: 0.5122\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8205 - accuracy: 0.7186 - val_loss: 1.6792 - val_accuracy: 0.5048\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8011 - accuracy: 0.7240 - val_loss: 1.6489 - val_accuracy: 0.5070\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7808 - accuracy: 0.7315 - val_loss: 1.7217 - val_accuracy: 0.5170\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.7585 - accuracy: 0.7391 - val_loss: 1.7042 - val_accuracy: 0.5028\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7384 - accuracy: 0.7466 - val_loss: 1.6502 - val_accuracy: 0.4994\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.7216 - accuracy: 0.7552 - val_loss: 1.7358 - val_accuracy: 0.4980\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.6952 - accuracy: 0.7632 - val_loss: 1.7696 - val_accuracy: 0.5068\n",
      "Epoch 29/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.6908 - accuracy: 0.7658 - val_loss: 1.8088 - val_accuracy: 0.5056\n",
      "Epoch 30/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.6635 - accuracy: 0.7766 - val_loss: 1.7958 - val_accuracy: 0.5096\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4638 - accuracy: 0.1082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4637835025787354, 0.10819999873638153]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\",overwrite=True, save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis = 0)\n",
    "X_stds = X_train.std(axis = 0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid),epochs=100, \n",
    "          callbacks = callbacks, workers= 0,batch_size=128)\n",
    "\n",
    "loaded_model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "loaded_model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.lecun_normal(), activation=tf.nn.selu))\n",
    "model.add(keras.layers.AlphaDropout(rate = 0.1))\n",
    "model.add(keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/352 [..............................] - ETA: 41s - loss: 2.9467 - accuracy: 0.1133WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.2201s). Check your callbacks.\n",
      "352/352 [==============================] - 5s 15ms/step - loss: 1.9106 - accuracy: 0.3260 - val_loss: 1.7207 - val_accuracy: 0.3972\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.6238 - accuracy: 0.4242 - val_loss: 1.5763 - val_accuracy: 0.4428\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.5157 - accuracy: 0.4643 - val_loss: 1.5571 - val_accuracy: 0.4486\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.4415 - accuracy: 0.4902 - val_loss: 1.5019 - val_accuracy: 0.4838\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.3747 - accuracy: 0.5143 - val_loss: 1.5637 - val_accuracy: 0.4660\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.3181 - accuracy: 0.5341 - val_loss: 1.5202 - val_accuracy: 0.4818\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.2661 - accuracy: 0.5553 - val_loss: 1.5395 - val_accuracy: 0.4872\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.2233 - accuracy: 0.5688 - val_loss: 1.5140 - val_accuracy: 0.4900\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.1832 - accuracy: 0.5840 - val_loss: 1.4886 - val_accuracy: 0.4938\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.1442 - accuracy: 0.5991 - val_loss: 1.5261 - val_accuracy: 0.5118\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.1046 - accuracy: 0.6140 - val_loss: 1.5646 - val_accuracy: 0.5028\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.0659 - accuracy: 0.6268 - val_loss: 1.5728 - val_accuracy: 0.4934\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.0296 - accuracy: 0.6389 - val_loss: 1.6267 - val_accuracy: 0.5070\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.9970 - accuracy: 0.6506 - val_loss: 1.5758 - val_accuracy: 0.5078\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 0.9670 - accuracy: 0.6624 - val_loss: 1.7189 - val_accuracy: 0.5002\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.9361 - accuracy: 0.6722 - val_loss: 1.7578 - val_accuracy: 0.5106\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9053 - accuracy: 0.6838 - val_loss: 1.7249 - val_accuracy: 0.5134\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8732 - accuracy: 0.6960 - val_loss: 1.7652 - val_accuracy: 0.5092\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8496 - accuracy: 0.7027 - val_loss: 1.7726 - val_accuracy: 0.5072\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8265 - accuracy: 0.7118 - val_loss: 1.7875 - val_accuracy: 0.5032\n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.7983 - accuracy: 0.7221 - val_loss: 1.8693 - val_accuracy: 0.5048\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7748 - accuracy: 0.7328 - val_loss: 1.8845 - val_accuracy: 0.5092\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 0.7516 - accuracy: 0.7374 - val_loss: 1.9533 - val_accuracy: 0.4936\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.7216 - accuracy: 0.7495 - val_loss: 1.8846 - val_accuracy: 0.5012\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.7036 - accuracy: 0.7562 - val_loss: 2.0010 - val_accuracy: 0.4936\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.6900 - accuracy: 0.7626 - val_loss: 1.9881 - val_accuracy: 0.4960\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.6582 - accuracy: 0.7737 - val_loss: 2.0334 - val_accuracy: 0.5012\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.6511 - accuracy: 0.7777 - val_loss: 2.0059 - val_accuracy: 0.4992\n",
      "Epoch 29/100\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.6296 - accuracy: 0.7813 - val_loss: 2.2260 - val_accuracy: 0.4988\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4886 - accuracy: 0.1370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4885591268539429, 0.13699999451637268]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_alpha_dropout_model.h5\",overwrite=True, save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks,batch_size=128)\n",
    "\n",
    "model = keras.models.load_model(\"cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples = 10):\n",
    "    y_probas = [mc_model.predict(X) for _ in range(n_samples)]\n",
    "    return np.mean(y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples = 10):\n",
    "    y_probas = mc_dropout_predict_classes(mc_model, X, n_samples)\n",
    "    return np.argmax(y_probas, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "360eb45faca1e4dfefc4f13aa9499776008d91528b4d443d812d58097d713eb4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('d2l': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
